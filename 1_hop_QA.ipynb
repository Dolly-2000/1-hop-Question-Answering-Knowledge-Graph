{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Dolly Pandey(24AI60R22)"
      ],
      "metadata": {
        "id": "rBw74wfkPV6r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlNEwuIAAago",
        "outputId": "0a8dbe01-28da-4ac9-fc7f-4133595bbc9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pykeen\n",
            "  Downloading pykeen-1.11.1-py3-none-any.whl.metadata (85 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.9/85.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json (from pykeen)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pykeen) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from pykeen) (1.16.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from pykeen) (8.2.1)\n",
            "Collecting click_default_group (from pykeen)\n",
            "  Downloading click_default_group-1.2.4-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pykeen) (1.6.1)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from pykeen) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pykeen) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pykeen) (2.32.3)\n",
            "Collecting optuna>=2.0.0 (from pykeen)\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pykeen) (2.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from pykeen) (0.9.0)\n",
            "Collecting more_click (from pykeen)\n",
            "  Downloading more_click-0.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from pykeen) (10.7.0)\n",
            "Collecting pystow>=0.4.3 (from pykeen)\n",
            "  Downloading pystow-0.7.6-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting docdata>=0.0.5 (from pykeen)\n",
            "  Downloading docdata-0.0.5-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting class_resolver>=0.6.0 (from pykeen)\n",
            "  Downloading class_resolver-0.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from pykeen) (6.0.2)\n",
            "Collecting torch_max_mem>=0.1.4 (from pykeen)\n",
            "  Downloading torch_max_mem-0.1.4-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting torch-ppr>=0.0.7 (from pykeen)\n",
            "  Downloading torch_ppr-0.0.8-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from pykeen) (4.14.1)\n",
            "Collecting alembic>=1.5.0 (from optuna>=2.0.0->pykeen)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna>=2.0.0->pykeen)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna>=2.0.0->pykeen) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna>=2.0.0->pykeen) (2.0.43)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->pykeen) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->pykeen) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->pykeen) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->pykeen) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->pykeen) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->pykeen) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->pykeen) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->pykeen)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->pykeen)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->pykeen)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->pykeen)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->pykeen)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->pykeen)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->pykeen)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->pykeen)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->pykeen)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->pykeen) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.0->pykeen)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->pykeen) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->pykeen)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->pykeen) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->pykeen) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->pykeen) (1.3.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->pykeen)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->pykeen)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pykeen) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pykeen) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pykeen) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pykeen) (2025.8.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pykeen) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pykeen) (3.6.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=2.0.0->pykeen) (1.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->pykeen) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna>=2.0.0->pykeen) (3.2.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->pykeen)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->pykeen) (3.0.2)\n",
            "Downloading pykeen-1.11.1-py3-none-any.whl (730 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.3/730.3 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading class_resolver-0.6.0-py3-none-any.whl (31 kB)\n",
            "Downloading docdata-0.0.5-py3-none-any.whl (9.2 kB)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pystow-0.7.6-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_max_mem-0.1.4-py3-none-any.whl (13 kB)\n",
            "Downloading torch_ppr-0.0.8-py3-none-any.whl (12 kB)\n",
            "Downloading click_default_group-1.2.4-py2.py3-none-any.whl (4.1 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading more_click-0.1.2-py3-none-any.whl (6.7 kB)\n",
            "Downloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, more_click, marshmallow, docdata, colorlog, click_default_group, class_resolver, typing-inspect, pystow, nvidia-cusparse-cu12, nvidia-cudnn-cu12, alembic, optuna, nvidia-cusolver-cu12, dataclasses-json, torch_max_mem, torch-ppr, pykeen\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed alembic-1.16.4 class_resolver-0.6.0 click_default_group-1.2.4 colorlog-6.9.0 dataclasses-json-0.6.7 docdata-0.0.5 marshmallow-3.26.1 more_click-0.1.2 mypy-extensions-1.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 optuna-4.5.0 pykeen-1.11.1 pystow-0.7.6 torch-ppr-0.0.8 torch_max_mem-0.1.4 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "#installing pykeen\n",
        "!pip install pykeen\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import numpy as np\n",
        "from pykeen.datasets import Nations, Kinships\n",
        "from pykeen.evaluation import RankBasedEvaluator\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n"
      ],
      "metadata": {
        "id": "N_5Uf8D_B0_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ef82fc-0833-4cf7-d692-093e09faa894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pykeen.utils:Using opt_einsum\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Nations dataset\n",
        "nations_dataset = Nations()\n",
        "kinships_dataset = Kinships()\n",
        "\n",
        "# Get the entity and relation mappings\n",
        "nations_entity2id = nations_dataset.training.entity_to_id\n",
        "nations_relation2id = nations_dataset.training.relation_to_id\n",
        "kinships_entity2id = kinships_dataset.training.entity_to_id\n",
        "kinships_relation2id = kinships_dataset.training.relation_to_id\n",
        "\n",
        "# All entities and relations\n",
        "nations_entities = list(nations_entity2id.values())\n",
        "nations_relations = list(nations_relation2id.values())\n",
        "\n",
        "kinships_entities = list(kinships_entity2id.values())\n",
        "kinships_relations = list(kinships_relation2id.values())\n"
      ],
      "metadata": {
        "id": "ikNRpuQ9Au9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nations_entity2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIQCssMwWjpN",
        "outputId": "908d7ead-c042-4b8b-fb19-ca1498a9d863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'brazil': 0,\n",
              " 'burma': 1,\n",
              " 'china': 2,\n",
              " 'cuba': 3,\n",
              " 'egypt': 4,\n",
              " 'india': 5,\n",
              " 'indonesia': 6,\n",
              " 'israel': 7,\n",
              " 'jordan': 8,\n",
              " 'netherlands': 9,\n",
              " 'poland': 10,\n",
              " 'uk': 11,\n",
              " 'usa': 12,\n",
              " 'ussr': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nations_relation2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKh2iVeDWxyU",
        "outputId": "f6d4a0b3-ccfb-4d4d-a001-19f791f37638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accusation': 0,\n",
              " 'aidenemy': 1,\n",
              " 'attackembassy': 2,\n",
              " 'blockpositionindex': 3,\n",
              " 'booktranslations': 4,\n",
              " 'boycottembargo': 5,\n",
              " 'commonbloc0': 6,\n",
              " 'commonbloc1': 7,\n",
              " 'commonbloc2': 8,\n",
              " 'conferences': 9,\n",
              " 'dependent': 10,\n",
              " 'duration': 11,\n",
              " 'economicaid': 12,\n",
              " 'eemigrants': 13,\n",
              " 'embassy': 14,\n",
              " 'emigrants3': 15,\n",
              " 'expeldiplomats': 16,\n",
              " 'exportbooks': 17,\n",
              " 'exports3': 18,\n",
              " 'independence': 19,\n",
              " 'intergovorgs': 20,\n",
              " 'intergovorgs3': 21,\n",
              " 'lostterritory': 22,\n",
              " 'militaryactions': 23,\n",
              " 'militaryalliance': 24,\n",
              " 'negativebehavior': 25,\n",
              " 'negativecomm': 26,\n",
              " 'ngo': 27,\n",
              " 'ngoorgs3': 28,\n",
              " 'nonviolentbehavior': 29,\n",
              " 'officialvisits': 30,\n",
              " 'pprotests': 31,\n",
              " 'relbooktranslations': 32,\n",
              " 'reldiplomacy': 33,\n",
              " 'releconomicaid': 34,\n",
              " 'relemigrants': 35,\n",
              " 'relexportbooks': 36,\n",
              " 'relexports': 37,\n",
              " 'relintergovorgs': 38,\n",
              " 'relngo': 39,\n",
              " 'relstudents': 40,\n",
              " 'reltourism': 41,\n",
              " 'reltreaties': 42,\n",
              " 'severdiplomatic': 43,\n",
              " 'students': 44,\n",
              " 'timesinceally': 45,\n",
              " 'timesincewar': 46,\n",
              " 'tourism': 47,\n",
              " 'tourism3': 48,\n",
              " 'treaties': 49,\n",
              " 'unoffialacts': 50,\n",
              " 'unweightedunvote': 51,\n",
              " 'violentactions': 52,\n",
              " 'warning': 53,\n",
              " 'weightedunvote': 54}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kinships_entity2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeXsjd9jW2pQ",
        "outputId": "6a622978-a429-4641-dc18-56fb5d6a1b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'person0': 0,\n",
              " 'person1': 1,\n",
              " 'person10': 2,\n",
              " 'person100': 3,\n",
              " 'person101': 4,\n",
              " 'person102': 5,\n",
              " 'person103': 6,\n",
              " 'person11': 7,\n",
              " 'person12': 8,\n",
              " 'person13': 9,\n",
              " 'person14': 10,\n",
              " 'person15': 11,\n",
              " 'person16': 12,\n",
              " 'person17': 13,\n",
              " 'person18': 14,\n",
              " 'person19': 15,\n",
              " 'person2': 16,\n",
              " 'person20': 17,\n",
              " 'person21': 18,\n",
              " 'person22': 19,\n",
              " 'person23': 20,\n",
              " 'person24': 21,\n",
              " 'person25': 22,\n",
              " 'person26': 23,\n",
              " 'person27': 24,\n",
              " 'person28': 25,\n",
              " 'person29': 26,\n",
              " 'person3': 27,\n",
              " 'person30': 28,\n",
              " 'person31': 29,\n",
              " 'person32': 30,\n",
              " 'person33': 31,\n",
              " 'person34': 32,\n",
              " 'person35': 33,\n",
              " 'person36': 34,\n",
              " 'person37': 35,\n",
              " 'person38': 36,\n",
              " 'person39': 37,\n",
              " 'person4': 38,\n",
              " 'person40': 39,\n",
              " 'person41': 40,\n",
              " 'person42': 41,\n",
              " 'person43': 42,\n",
              " 'person44': 43,\n",
              " 'person45': 44,\n",
              " 'person46': 45,\n",
              " 'person47': 46,\n",
              " 'person48': 47,\n",
              " 'person49': 48,\n",
              " 'person5': 49,\n",
              " 'person50': 50,\n",
              " 'person51': 51,\n",
              " 'person52': 52,\n",
              " 'person53': 53,\n",
              " 'person54': 54,\n",
              " 'person55': 55,\n",
              " 'person56': 56,\n",
              " 'person57': 57,\n",
              " 'person58': 58,\n",
              " 'person59': 59,\n",
              " 'person6': 60,\n",
              " 'person60': 61,\n",
              " 'person61': 62,\n",
              " 'person62': 63,\n",
              " 'person63': 64,\n",
              " 'person64': 65,\n",
              " 'person65': 66,\n",
              " 'person66': 67,\n",
              " 'person67': 68,\n",
              " 'person68': 69,\n",
              " 'person69': 70,\n",
              " 'person7': 71,\n",
              " 'person70': 72,\n",
              " 'person71': 73,\n",
              " 'person72': 74,\n",
              " 'person73': 75,\n",
              " 'person74': 76,\n",
              " 'person75': 77,\n",
              " 'person76': 78,\n",
              " 'person77': 79,\n",
              " 'person78': 80,\n",
              " 'person79': 81,\n",
              " 'person8': 82,\n",
              " 'person80': 83,\n",
              " 'person81': 84,\n",
              " 'person82': 85,\n",
              " 'person83': 86,\n",
              " 'person84': 87,\n",
              " 'person85': 88,\n",
              " 'person86': 89,\n",
              " 'person87': 90,\n",
              " 'person88': 91,\n",
              " 'person89': 92,\n",
              " 'person9': 93,\n",
              " 'person90': 94,\n",
              " 'person91': 95,\n",
              " 'person92': 96,\n",
              " 'person93': 97,\n",
              " 'person94': 98,\n",
              " 'person95': 99,\n",
              " 'person96': 100,\n",
              " 'person97': 101,\n",
              " 'person98': 102,\n",
              " 'person99': 103}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kinships_relation2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0jqGrQPW51x",
        "outputId": "8345da3b-b278-45df-8e24-48aa79e74cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'term0': 0,\n",
              " 'term1': 1,\n",
              " 'term10': 2,\n",
              " 'term11': 3,\n",
              " 'term12': 4,\n",
              " 'term13': 5,\n",
              " 'term14': 6,\n",
              " 'term15': 7,\n",
              " 'term16': 8,\n",
              " 'term17': 9,\n",
              " 'term18': 10,\n",
              " 'term19': 11,\n",
              " 'term2': 12,\n",
              " 'term20': 13,\n",
              " 'term21': 14,\n",
              " 'term22': 15,\n",
              " 'term24': 16,\n",
              " 'term25': 17,\n",
              " 'term3': 18,\n",
              " 'term4': 19,\n",
              " 'term5': 20,\n",
              " 'term6': 21,\n",
              " 'term7': 22,\n",
              " 'term8': 23,\n",
              " 'term9': 24}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Nations dataset splits\n",
        "nations_train_triples = nations_dataset.training.mapped_triples\n",
        "nations_valid_triples = nations_dataset.validation.mapped_triples\n",
        "nations_test_triples = nations_dataset.testing.mapped_triples\n",
        "\n",
        "# Kinships dataset splits\n",
        "kinships_train_triples = kinships_dataset.training.mapped_triples\n",
        "kinships_valid_triples = kinships_dataset.validation.mapped_triples\n",
        "kinships_test_triples = kinships_dataset.testing.mapped_triples\n"
      ],
      "metadata": {
        "id": "FrutBlm3A096"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nations_test_triples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJZgy1VTk_Hi",
        "outputId": "a9aa8172-82e6-4a30-fa1a-df970f6ab01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  7,  5],\n",
              "        [ 0, 14, 11],\n",
              "        [ 0, 18, 12],\n",
              "        [ 0, 20,  3],\n",
              "        [ 0, 20, 10],\n",
              "        [ 0, 21, 12],\n",
              "        [ 1,  3, 12],\n",
              "        [ 1,  7,  0],\n",
              "        [ 1, 10, 11],\n",
              "        [ 1, 18,  5],\n",
              "        [ 1, 21,  6],\n",
              "        [ 1, 28,  7],\n",
              "        [ 1, 33,  4],\n",
              "        [ 1, 33,  6],\n",
              "        [ 1, 33, 13],\n",
              "        [ 1, 38,  4],\n",
              "        [ 1, 38,  7],\n",
              "        [ 1, 38, 12],\n",
              "        [ 1, 39,  7],\n",
              "        [ 1, 42,  2],\n",
              "        [ 1, 49,  2],\n",
              "        [ 2,  0, 11],\n",
              "        [ 2,  6,  0],\n",
              "        [ 2, 14,  1],\n",
              "        [ 2, 14,  4],\n",
              "        [ 2, 14,  6],\n",
              "        [ 2, 21,  5],\n",
              "        [ 2, 21, 12],\n",
              "        [ 2, 21, 13],\n",
              "        [ 2, 26,  5],\n",
              "        [ 2, 30,  1],\n",
              "        [ 2, 30,  6],\n",
              "        [ 2, 37,  3],\n",
              "        [ 2, 37, 13],\n",
              "        [ 2, 38,  0],\n",
              "        [ 2, 45,  0],\n",
              "        [ 3, 19, 12],\n",
              "        [ 3, 21, 11],\n",
              "        [ 3, 25, 11],\n",
              "        [ 3, 28,  7],\n",
              "        [ 3, 30,  2],\n",
              "        [ 3, 33,  2],\n",
              "        [ 3, 33,  4],\n",
              "        [ 3, 37, 13],\n",
              "        [ 3, 38,  4],\n",
              "        [ 3, 42,  2],\n",
              "        [ 3, 42, 11],\n",
              "        [ 3, 46, 12],\n",
              "        [ 3, 48, 13],\n",
              "        [ 4,  7,  0],\n",
              "        [ 4,  7, 11],\n",
              "        [ 4,  8,  5],\n",
              "        [ 4, 14,  1],\n",
              "        [ 4, 14,  3],\n",
              "        [ 4, 14, 11],\n",
              "        [ 4, 14, 13],\n",
              "        [ 4, 19,  0],\n",
              "        [ 4, 19, 12],\n",
              "        [ 4, 25,  7],\n",
              "        [ 4, 28,  0],\n",
              "        [ 4, 28,  9],\n",
              "        [ 4, 28, 12],\n",
              "        [ 4, 30, 13],\n",
              "        [ 4, 33, 12],\n",
              "        [ 4, 42, 10],\n",
              "        [ 4, 45, 13],\n",
              "        [ 4, 49,  2],\n",
              "        [ 4, 49,  6],\n",
              "        [ 5,  7,  2],\n",
              "        [ 5,  7, 10],\n",
              "        [ 5, 20,  1],\n",
              "        [ 5, 20,  4],\n",
              "        [ 5, 20,  7],\n",
              "        [ 5, 29,  2],\n",
              "        [ 5, 37, 11],\n",
              "        [ 5, 37, 12],\n",
              "        [ 5, 37, 13],\n",
              "        [ 5, 38,  0],\n",
              "        [ 5, 42, 12],\n",
              "        [ 5, 44, 12],\n",
              "        [ 5, 45,  0],\n",
              "        [ 5, 45,  3],\n",
              "        [ 6,  0, 11],\n",
              "        [ 6,  7,  9],\n",
              "        [ 6,  8,  1],\n",
              "        [ 6, 14,  1],\n",
              "        [ 6, 14,  3],\n",
              "        [ 6, 16,  3],\n",
              "        [ 6, 23, 11],\n",
              "        [ 6, 24, 12],\n",
              "        [ 6, 26,  2],\n",
              "        [ 6, 26, 11],\n",
              "        [ 6, 28,  5],\n",
              "        [ 6, 28,  9],\n",
              "        [ 6, 33,  4],\n",
              "        [ 6, 33, 11],\n",
              "        [ 6, 39,  3],\n",
              "        [ 6, 39, 12],\n",
              "        [ 6, 42,  2],\n",
              "        [ 6, 44, 12],\n",
              "        [ 6, 52, 11],\n",
              "        [ 7,  4, 13],\n",
              "        [ 7,  7,  3],\n",
              "        [ 7,  7,  9],\n",
              "        [ 7, 14,  0],\n",
              "        [ 7, 20,  4],\n",
              "        [ 7, 21,  0],\n",
              "        [ 7, 21,  4],\n",
              "        [ 7, 21, 12],\n",
              "        [ 7, 28,  0],\n",
              "        [ 7, 39,  5],\n",
              "        [ 7, 39, 12],\n",
              "        [ 7, 46,  8],\n",
              "        [ 8,  8,  6],\n",
              "        [ 8, 21,  7],\n",
              "        [ 8, 28,  9],\n",
              "        [ 8, 28, 12],\n",
              "        [ 8, 30,  4],\n",
              "        [ 8, 33, 12],\n",
              "        [ 8, 38,  3],\n",
              "        [ 8, 38, 10],\n",
              "        [ 8, 39,  0],\n",
              "        [ 8, 39, 12],\n",
              "        [ 8, 42,  6],\n",
              "        [ 8, 54, 11],\n",
              "        [ 9,  6,  2],\n",
              "        [ 9,  7,  1],\n",
              "        [ 9,  8, 11],\n",
              "        [ 9, 14,  2],\n",
              "        [ 9, 14,  5],\n",
              "        [ 9, 14, 13],\n",
              "        [ 9, 20,  6],\n",
              "        [ 9, 22,  6],\n",
              "        [ 9, 27,  5],\n",
              "        [ 9, 28,  5],\n",
              "        [ 9, 36, 11],\n",
              "        [ 9, 38, 11],\n",
              "        [ 9, 48, 11],\n",
              "        [ 9, 48, 13],\n",
              "        [ 9, 49, 12],\n",
              "        [10,  8, 13],\n",
              "        [10, 19, 11],\n",
              "        [10, 20,  7],\n",
              "        [10, 21,  7],\n",
              "        [10, 27,  5],\n",
              "        [10, 28, 13],\n",
              "        [10, 33,  3],\n",
              "        [10, 33,  5],\n",
              "        [10, 33, 12],\n",
              "        [10, 37, 12],\n",
              "        [10, 38, 12],\n",
              "        [10, 42, 13],\n",
              "        [10, 54,  9],\n",
              "        [10, 54, 11],\n",
              "        [11,  9,  6],\n",
              "        [11, 11,  6],\n",
              "        [11, 14,  9],\n",
              "        [11, 21,  0],\n",
              "        [11, 21,  9],\n",
              "        [11, 27, 10],\n",
              "        [11, 31, 13],\n",
              "        [11, 39, 12],\n",
              "        [11, 45,  3],\n",
              "        [11, 45,  4],\n",
              "        [11, 45, 12],\n",
              "        [11, 45, 13],\n",
              "        [11, 48,  4],\n",
              "        [11, 51,  8],\n",
              "        [11, 54,  3],\n",
              "        [12,  0,  3],\n",
              "        [12,  3, 13],\n",
              "        [12,  9,  6],\n",
              "        [12, 14,  0],\n",
              "        [12, 14, 11],\n",
              "        [12, 19,  2],\n",
              "        [12, 24,  9],\n",
              "        [12, 24, 11],\n",
              "        [12, 25,  4],\n",
              "        [12, 26,  0],\n",
              "        [12, 28,  9],\n",
              "        [12, 28, 11],\n",
              "        [12, 30,  6],\n",
              "        [12, 41,  4],\n",
              "        [12, 41,  5],\n",
              "        [12, 45,  3],\n",
              "        [12, 45,  9],\n",
              "        [12, 51,  7],\n",
              "        [12, 54,  3],\n",
              "        [12, 54,  7],\n",
              "        [12, 54, 13],\n",
              "        [13,  3,  1],\n",
              "        [13,  3, 11],\n",
              "        [13,  4, 12],\n",
              "        [13, 14,  9],\n",
              "        [13, 19,  2],\n",
              "        [13, 32, 12],\n",
              "        [13, 33, 12],\n",
              "        [13, 38,  0],\n",
              "        [13, 39, 10],\n",
              "        [13, 45,  0],\n",
              "        [13, 45,  2]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking dimensions of dataset splits\n",
        "print(nations_train_triples.shape)\n",
        "print(nations_valid_triples.shape)\n",
        "print(nations_test_triples.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bxs_uNoUooI1",
        "outputId": "19f50f07-8478-4e5b-fbc2-af403ccc6edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1592, 3])\n",
            "torch.Size([199, 3])\n",
            "torch.Size([201, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(nations_train_triples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97n-B5D-oymN",
        "outputId": "476bb978-8a98-4098-f1ea-1b309dee8d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  3,  2],\n",
            "        [ 0,  3,  3],\n",
            "        [ 0,  3, 10],\n",
            "        ...,\n",
            "        [13, 54,  9],\n",
            "        [13, 54, 11],\n",
            "        [13, 54, 12]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Define TransE model***"
      ],
      "metadata": {
        "id": "F4XE3prHCX7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function will be used for bernoulli negative sampling\n",
        "#this will be used to corrupt head or tail entity randomly while generating negative triplets\n",
        "def calculate_relation_probabilities(triples, num_relations):\n",
        "    relation_counts = defaultdict(lambda: {'head': defaultdict(int), 'tail': defaultdict(int)})\n",
        "    relation_probabilities = {}\n",
        "\n",
        "    for h, r, t in triples.numpy():\n",
        "        relation_counts[r]['head'][h] += 1\n",
        "        relation_counts[r]['tail'][t] += 1\n",
        "\n",
        "    for r in range(num_relations):\n",
        "        head_count = len(relation_counts[r]['head'])\n",
        "        tail_count = len(relation_counts[r]['tail'])\n",
        "        tph = tail_count / head_count if head_count != 0 else 0\n",
        "        hpt = head_count / tail_count if tail_count != 0 else 0\n",
        "        prob = tph / (tph + hpt) if (tph + hpt) != 0 else 0.5\n",
        "        relation_probabilities[r] = prob\n",
        "\n",
        "    return relation_probabilities\n"
      ],
      "metadata": {
        "id": "lhQlDRh3A7km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining my transE class\n",
        "class TransE(nn.Module):\n",
        "    def __init__(self, num_entities, num_relations, embedding_dim, margin):\n",
        "        #intializign all the parameters of my class\n",
        "        super(TransE, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.margin = margin\n",
        "        self.num_entities = num_entities\n",
        "        self.num_relations = num_relations\n",
        "\n",
        "        # Initialize entity and relation embeddings\n",
        "        self.entity_embeddings = nn.Embedding(num_entities, embedding_dim)\n",
        "        self.relation_embeddings = nn.Embedding(num_relations, embedding_dim)\n",
        "\n",
        "        # Initialize embeddings randomly in the range(-6/sqrt(d) to 6/sqrt(d))\n",
        "        nn.init.xavier_uniform_(self.entity_embeddings.weight.data)\n",
        "        nn.init.xavier_uniform_(self.relation_embeddings.weight.data)\n",
        "\n",
        "    def forward(self, positive_triples, negative_triples):\n",
        "        # Get embeddings\n",
        "        pos_heads = self.entity_embeddings(positive_triples[:, 0])\n",
        "        pos_relations = self.relation_embeddings(positive_triples[:, 1])\n",
        "        pos_tails = self.entity_embeddings(positive_triples[:, 2])\n",
        "\n",
        "        neg_heads = self.entity_embeddings(negative_triples[:, 0])\n",
        "        neg_relations = self.relation_embeddings(negative_triples[:, 1])\n",
        "        neg_tails = self.entity_embeddings(negative_triples[:, 2])\n",
        "\n",
        "        # Calculate scores\n",
        "        pos_scores = torch.norm(pos_heads + pos_relations - pos_tails, p=1, dim=1)\n",
        "        neg_scores = torch.norm(neg_heads + neg_relations - neg_tails, p=1, dim=1)\n",
        "\n",
        "        return pos_scores, neg_scores\n",
        "    #prediction function\n",
        "    def predict(self, triples):\n",
        "        heads = self.entity_embeddings(triples[:, 0])\n",
        "        relations = self.relation_embeddings(triples[:, 1])\n",
        "        tails = self.entity_embeddings(triples[:, 2])\n",
        "        scores = torch.norm(heads + relations - tails, p=1, dim=1)\n",
        "        return scores\n"
      ],
      "metadata": {
        "id": "Tys9IWz_BpiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the training function for transE\n",
        "#attributes here will be the triplets and the bernoulli negative sampling probability(based on which I'll generate negative samples)\n",
        "#I'll generate negative samples withing this function only\n",
        "def train_transe(model, optimizer, train_triples, all_entities, relation_probabilities, num_epochs=50, batch_size=128):\n",
        "    # defining loss function\n",
        "    criterion = nn.MarginRankingLoss(margin=model.margin, reduction='mean')\n",
        "    loss_value_for_transE = 0 #total loss for our training\n",
        "    for epoch in range(num_epochs): #for each epoch train the model\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        permutation = torch.randperm(train_triples.size()[0]).to(train_triples.device)\n",
        "        for i in range(0, train_triples.size()[0], batch_size):\n",
        "            indices = permutation[i:i+batch_size]\n",
        "            batch = train_triples[indices]\n",
        "            positive_triples = batch\n",
        "\n",
        "            # Generate negative samples\n",
        "            negative_triples = []\n",
        "            for triple in batch:\n",
        "                # Move the tensor to CPU before converting to NumPy or else It will throw error\n",
        "                h, r, t = triple.cpu().numpy()\n",
        "                prob = relation_probabilities[r]\n",
        "                # if probability is lower than threshold then replace head else replace tail\n",
        "                if random.random() < prob:\n",
        "                    # Replace head\n",
        "                    h_neg = random.choice(all_entities)\n",
        "                    negative_triples.append([h_neg, r, t])\n",
        "                else:\n",
        "                    # Replace tail\n",
        "                    t_neg = random.choice(all_entities)\n",
        "                    negative_triples.append([h, r, t_neg])\n",
        "            negative_triples = torch.tensor(negative_triples, dtype=torch.long, device=train_triples.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            pos_scores, neg_scores = model(positive_triples, negative_triples)\n",
        "            target = torch.tensor([-1], dtype=torch.long, device=train_triples.device)\n",
        "            loss = criterion(pos_scores, neg_scores, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            loss_value_for_transE = epoch_loss\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}\")\n",
        "    return loss_value_for_transE #return loss value"
      ],
      "metadata": {
        "id": "v46mIQvwDWYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TransR model implementation**"
      ],
      "metadata": {
        "id": "WsLuJdppClKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the implementation of transR model\n",
        "class TransR(nn.Module):\n",
        "    def __init__(self, num_entities, num_relations, ent_embedding_dim, rel_embedding_dim, margin):\n",
        "        super(TransR, self).__init__()\n",
        "        self.ent_embedding_dim = ent_embedding_dim\n",
        "        self.rel_embedding_dim = rel_embedding_dim\n",
        "        self.margin = margin\n",
        "        self.num_entities = num_entities\n",
        "        self.num_relations = num_relations\n",
        "\n",
        "        # Initialize entity and relation embeddings\n",
        "        self.entity_embeddings = nn.Embedding(num_entities, ent_embedding_dim)\n",
        "        self.relation_embeddings = nn.Embedding(num_relations, rel_embedding_dim)\n",
        "\n",
        "        # Initialize projection matrices for each relation\n",
        "        self.proj_matrices = nn.Embedding(num_relations, ent_embedding_dim * rel_embedding_dim)\n",
        "\n",
        "        # Initialize embeddings\n",
        "        nn.init.xavier_uniform_(self.entity_embeddings.weight.data)\n",
        "        nn.init.xavier_uniform_(self.relation_embeddings.weight.data)\n",
        "        nn.init.xavier_uniform_(self.proj_matrices.weight.data)\n",
        "\n",
        "    def forward(self, positive_triples, negative_triples):\n",
        "        # Get embeddings\n",
        "        pos_heads = self.entity_embeddings(positive_triples[:, 0])\n",
        "        pos_relations = self.relation_embeddings(positive_triples[:, 1])\n",
        "        pos_tails = self.entity_embeddings(positive_triples[:, 2])\n",
        "        pos_proj = self.proj_matrices(positive_triples[:, 1]).view(-1, self.rel_embedding_dim, self.ent_embedding_dim)\n",
        "\n",
        "        neg_heads = self.entity_embeddings(negative_triples[:, 0])\n",
        "        neg_relations = self.relation_embeddings(negative_triples[:, 1])\n",
        "        neg_tails = self.entity_embeddings(negative_triples[:, 2])\n",
        "        neg_proj = self.proj_matrices(negative_triples[:, 1]).view(-1, self.rel_embedding_dim, self.ent_embedding_dim)\n",
        "\n",
        "        # Project entities into relation space\n",
        "        pos_heads_proj = torch.bmm(pos_proj, pos_heads.unsqueeze(2)).squeeze(2)\n",
        "        pos_tails_proj = torch.bmm(pos_proj, pos_tails.unsqueeze(2)).squeeze(2)\n",
        "\n",
        "        neg_heads_proj = torch.bmm(neg_proj, neg_heads.unsqueeze(2)).squeeze(2)\n",
        "        neg_tails_proj = torch.bmm(neg_proj, neg_tails.unsqueeze(2)).squeeze(2)\n",
        "\n",
        "        # Calculate scores\n",
        "        pos_scores = torch.norm(pos_heads_proj + pos_relations - pos_tails_proj, p=1, dim=1)\n",
        "        neg_scores = torch.norm(neg_heads_proj + neg_relations - neg_tails_proj, p=1, dim=1)\n",
        "\n",
        "        return pos_scores, neg_scores\n",
        "    #prediction function\n",
        "    def predict(self, triples):\n",
        "        heads = self.entity_embeddings(triples[:, 0])\n",
        "        relations = self.relation_embeddings(triples[:, 1])\n",
        "        tails = self.entity_embeddings(triples[:, 2])\n",
        "        proj = self.proj_matrices(triples[:, 1]).view(-1, self.rel_embedding_dim, self.ent_embedding_dim)\n",
        "\n",
        "        heads_proj = torch.bmm(proj, heads.unsqueeze(2)).squeeze(2)\n",
        "        tails_proj = torch.bmm(proj, tails.unsqueeze(2)).squeeze(2)\n",
        "\n",
        "        scores = torch.norm(heads_proj + relations - tails_proj, p=1, dim=1)\n",
        "        return scores\n"
      ],
      "metadata": {
        "id": "RdKwUT8vCoJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to train transR model, here I take a true triplet and generate false triplets inside the function only and\n",
        "#calculate the embeedings using those pairs\n",
        "def train_transr(model, optimizer, train_triples, all_entities, relation_probabilities, num_epochs=50, batch_size=128):\n",
        "    criterion = nn.MarginRankingLoss(margin=model.margin, reduction='mean') #loss function\n",
        "    loss_value_for_transR = 0 #this stores the loss values\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        permutation = torch.randperm(train_triples.size(0))\n",
        "\n",
        "        for i in range(0, train_triples.size(0), batch_size):\n",
        "            indices = permutation[i:i+batch_size]\n",
        "            batch = train_triples[indices]\n",
        "            positive_triples = batch\n",
        "\n",
        "            # Generate negative samples\n",
        "            negative_triples = []\n",
        "            for triple in batch:\n",
        "                h, r, t = triple.cpu().numpy()\n",
        "                prob = relation_probabilities[r]\n",
        "                if random.random() < prob:\n",
        "                    # Replace head\n",
        "                    h_neg = random.choice(all_entities)\n",
        "                    negative_triples.append([h_neg, r, t])\n",
        "                else:\n",
        "                    # Replace tail\n",
        "                    t_neg = random.choice(all_entities)\n",
        "                    negative_triples.append([h, r, t_neg])\n",
        "\n",
        "            # Convert negative triples back to tensors and move to the same device\n",
        "            negative_triples = torch.tensor(negative_triples, dtype=torch.long, device=train_triples.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            pos_scores, neg_scores = model(positive_triples, negative_triples)\n",
        "            target = torch.tensor([-1], dtype=torch.long, device=train_triples.device)\n",
        "            loss = criterion(pos_scores, neg_scores, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            loss_value_for_transR = epoch_loss\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}\")\n",
        "    return loss_value_for_transR #return loss value"
      ],
      "metadata": {
        "id": "Vku_PLPsL1ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1-Hop question answering**"
      ],
      "metadata": {
        "id": "PjGoCSEMCxjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training and Evaluation on Nations Dataset**"
      ],
      "metadata": {
        "id": "P28EQhQ4C5sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TransE and TransR for nations Dataset"
      ],
      "metadata": {
        "id": "rWWdFU0rAhjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data to train the model\n",
        "train_triples = nations_train_triples\n",
        "test_triples = nations_test_triples\n",
        "\n",
        "num_entities = len(nations_entity2id)\n",
        "num_relations = len(nations_relation2id)\n",
        "all_entities = list(range(num_entities))\n",
        "\n",
        "# Calculate relation probabilities (bernoulli probability distribution)\n",
        "relation_probabilities = calculate_relation_probabilities(train_triples, num_relations)\n",
        "\n",
        "# Initialize model\n",
        "embedding_dim = 100\n",
        "device = 'cpu'\n",
        "\n",
        "#this variables will be used to check for best values of margin\n",
        "best_loss_value = float('inf')\n",
        "best_margin = None\n",
        "best_model = None\n",
        "\n",
        "# running the loop for 5 different values of margin\n",
        "for margin in range(1,6):\n",
        "    transe_model = TransE(num_entities, num_relations, embedding_dim, margin).to(device)\n",
        "    optimizer = optim.Adam(transe_model.parameters(), lr=0.001)\n",
        "    temp = train_transe(transe_model, optimizer, train_triples.to(device), all_entities, relation_probabilities, num_epochs=50)\n",
        "    if temp < best_loss_value:\n",
        "        best_margin = margin\n",
        "        best_loss_value = temp\n",
        "        best_model = transe_model\n",
        "\n",
        "print(f\"\\n\\nBest Loss Value: {best_loss_value}\")\n",
        "print(f\"Best Margin: {best_margin}\")\n",
        "transe_model = best_model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqPMBcn6C87K",
        "outputId": "a9356e9e-7553-448e-d156-f656e481c7bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 23.732425212860107\n",
            "Epoch 2/50, Loss: 21.161314606666565\n",
            "Epoch 3/50, Loss: 19.53388774394989\n",
            "Epoch 4/50, Loss: 18.85138690471649\n",
            "Epoch 5/50, Loss: 17.383930802345276\n",
            "Epoch 6/50, Loss: 17.50614619255066\n",
            "Epoch 7/50, Loss: 17.294175922870636\n",
            "Epoch 8/50, Loss: 15.29683244228363\n",
            "Epoch 9/50, Loss: 16.331761360168457\n",
            "Epoch 10/50, Loss: 15.18696254491806\n",
            "Epoch 11/50, Loss: 15.30686491727829\n",
            "Epoch 12/50, Loss: 14.857366919517517\n",
            "Epoch 13/50, Loss: 14.312826335430145\n",
            "Epoch 14/50, Loss: 14.149939000606537\n",
            "Epoch 15/50, Loss: 14.4413041472435\n",
            "Epoch 16/50, Loss: 13.68579888343811\n",
            "Epoch 17/50, Loss: 13.211588263511658\n",
            "Epoch 18/50, Loss: 12.855248808860779\n",
            "Epoch 19/50, Loss: 12.982048213481903\n",
            "Epoch 20/50, Loss: 12.717418372631073\n",
            "Epoch 21/50, Loss: 12.542447686195374\n",
            "Epoch 22/50, Loss: 12.309785068035126\n",
            "Epoch 23/50, Loss: 11.197456657886505\n",
            "Epoch 24/50, Loss: 11.239216268062592\n",
            "Epoch 25/50, Loss: 10.434967041015625\n",
            "Epoch 26/50, Loss: 11.0032958984375\n",
            "Epoch 27/50, Loss: 10.937808513641357\n",
            "Epoch 28/50, Loss: 11.247117102146149\n",
            "Epoch 29/50, Loss: 11.11086618900299\n",
            "Epoch 30/50, Loss: 10.773716628551483\n",
            "Epoch 31/50, Loss: 10.932152152061462\n",
            "Epoch 32/50, Loss: 10.379938304424286\n",
            "Epoch 33/50, Loss: 10.173807680606842\n",
            "Epoch 34/50, Loss: 9.790756583213806\n",
            "Epoch 35/50, Loss: 10.00628137588501\n",
            "Epoch 36/50, Loss: 9.951573193073273\n",
            "Epoch 37/50, Loss: 9.728863894939423\n",
            "Epoch 38/50, Loss: 10.020483374595642\n",
            "Epoch 39/50, Loss: 10.035111784934998\n",
            "Epoch 40/50, Loss: 9.543033301830292\n",
            "Epoch 41/50, Loss: 9.346827745437622\n",
            "Epoch 42/50, Loss: 8.891647219657898\n",
            "Epoch 43/50, Loss: 9.666320204734802\n",
            "Epoch 44/50, Loss: 9.152510583400726\n",
            "Epoch 45/50, Loss: 9.368302166461945\n",
            "Epoch 46/50, Loss: 9.561796247959137\n",
            "Epoch 47/50, Loss: 9.04392808675766\n",
            "Epoch 48/50, Loss: 9.166541993618011\n",
            "Epoch 49/50, Loss: 9.29715222120285\n",
            "Epoch 50/50, Loss: 9.300031423568726\n",
            "Epoch 1/50, Loss: 34.00194334983826\n",
            "Epoch 2/50, Loss: 31.77307415008545\n",
            "Epoch 3/50, Loss: 32.006245613098145\n",
            "Epoch 4/50, Loss: 28.4495689868927\n",
            "Epoch 5/50, Loss: 27.81557810306549\n",
            "Epoch 6/50, Loss: 28.59318709373474\n",
            "Epoch 7/50, Loss: 25.318801522254944\n",
            "Epoch 8/50, Loss: 26.439821600914\n",
            "Epoch 9/50, Loss: 26.293586373329163\n",
            "Epoch 10/50, Loss: 24.39032733440399\n",
            "Epoch 11/50, Loss: 24.600927591323853\n",
            "Epoch 12/50, Loss: 23.711078882217407\n",
            "Epoch 13/50, Loss: 24.223767399787903\n",
            "Epoch 14/50, Loss: 23.33442211151123\n",
            "Epoch 15/50, Loss: 22.623608469963074\n",
            "Epoch 16/50, Loss: 22.869261145591736\n",
            "Epoch 17/50, Loss: 23.11445188522339\n",
            "Epoch 18/50, Loss: 22.549745678901672\n",
            "Epoch 19/50, Loss: 22.512847661972046\n",
            "Epoch 20/50, Loss: 21.53042733669281\n",
            "Epoch 21/50, Loss: 23.215242385864258\n",
            "Epoch 22/50, Loss: 22.857404232025146\n",
            "Epoch 23/50, Loss: 21.114938378334045\n",
            "Epoch 24/50, Loss: 20.487078547477722\n",
            "Epoch 25/50, Loss: 21.690460085868835\n",
            "Epoch 26/50, Loss: 21.63135039806366\n",
            "Epoch 27/50, Loss: 20.622843742370605\n",
            "Epoch 28/50, Loss: 21.18336820602417\n",
            "Epoch 29/50, Loss: 20.799356937408447\n",
            "Epoch 30/50, Loss: 20.223299622535706\n",
            "Epoch 31/50, Loss: 21.27005136013031\n",
            "Epoch 32/50, Loss: 19.553669571876526\n",
            "Epoch 33/50, Loss: 19.509369730949402\n",
            "Epoch 34/50, Loss: 19.730058670043945\n",
            "Epoch 35/50, Loss: 19.5226469039917\n",
            "Epoch 36/50, Loss: 19.343565344810486\n",
            "Epoch 37/50, Loss: 20.391528725624084\n",
            "Epoch 38/50, Loss: 18.91111731529236\n",
            "Epoch 39/50, Loss: 19.01916193962097\n",
            "Epoch 40/50, Loss: 18.840959787368774\n",
            "Epoch 41/50, Loss: 19.039575815200806\n",
            "Epoch 42/50, Loss: 18.30532217025757\n",
            "Epoch 43/50, Loss: 18.270511388778687\n",
            "Epoch 44/50, Loss: 19.089348435401917\n",
            "Epoch 45/50, Loss: 18.166746973991394\n",
            "Epoch 46/50, Loss: 18.719624876976013\n",
            "Epoch 47/50, Loss: 18.47183609008789\n",
            "Epoch 48/50, Loss: 18.473942399024963\n",
            "Epoch 49/50, Loss: 17.890104293823242\n",
            "Epoch 50/50, Loss: 17.73206090927124\n",
            "Epoch 1/50, Loss: 44.70148229598999\n",
            "Epoch 2/50, Loss: 43.18510842323303\n",
            "Epoch 3/50, Loss: 40.54689025878906\n",
            "Epoch 4/50, Loss: 40.166898012161255\n",
            "Epoch 5/50, Loss: 39.13566565513611\n",
            "Epoch 6/50, Loss: 38.95518374443054\n",
            "Epoch 7/50, Loss: 39.11731719970703\n",
            "Epoch 8/50, Loss: 37.22649431228638\n",
            "Epoch 9/50, Loss: 35.49758720397949\n",
            "Epoch 10/50, Loss: 35.709662199020386\n",
            "Epoch 11/50, Loss: 36.55225729942322\n",
            "Epoch 12/50, Loss: 34.631282806396484\n",
            "Epoch 13/50, Loss: 35.44215655326843\n",
            "Epoch 14/50, Loss: 34.94951772689819\n",
            "Epoch 15/50, Loss: 34.40707492828369\n",
            "Epoch 16/50, Loss: 34.25562024116516\n",
            "Epoch 17/50, Loss: 34.09496307373047\n",
            "Epoch 18/50, Loss: 31.8081374168396\n",
            "Epoch 19/50, Loss: 31.794217109680176\n",
            "Epoch 20/50, Loss: 31.877508878707886\n",
            "Epoch 21/50, Loss: 31.910195350646973\n",
            "Epoch 22/50, Loss: 30.51223397254944\n",
            "Epoch 23/50, Loss: 31.37218689918518\n",
            "Epoch 24/50, Loss: 31.599022150039673\n",
            "Epoch 25/50, Loss: 31.098575592041016\n",
            "Epoch 26/50, Loss: 30.65504765510559\n",
            "Epoch 27/50, Loss: 31.311301708221436\n",
            "Epoch 28/50, Loss: 30.946877002716064\n",
            "Epoch 29/50, Loss: 31.617822289466858\n",
            "Epoch 30/50, Loss: 30.489615440368652\n",
            "Epoch 31/50, Loss: 30.3045494556427\n",
            "Epoch 32/50, Loss: 31.37457823753357\n",
            "Epoch 33/50, Loss: 30.3482027053833\n",
            "Epoch 34/50, Loss: 30.349578380584717\n",
            "Epoch 35/50, Loss: 30.37610626220703\n",
            "Epoch 36/50, Loss: 29.75460183620453\n",
            "Epoch 37/50, Loss: 30.384516954421997\n",
            "Epoch 38/50, Loss: 30.099483966827393\n",
            "Epoch 39/50, Loss: 29.207592725753784\n",
            "Epoch 40/50, Loss: 29.659504532814026\n",
            "Epoch 41/50, Loss: 29.865706205368042\n",
            "Epoch 42/50, Loss: 28.916534066200256\n",
            "Epoch 43/50, Loss: 29.25078845024109\n",
            "Epoch 44/50, Loss: 28.222225069999695\n",
            "Epoch 45/50, Loss: 29.769097328186035\n",
            "Epoch 46/50, Loss: 29.298222303390503\n",
            "Epoch 47/50, Loss: 28.524524450302124\n",
            "Epoch 48/50, Loss: 28.467044830322266\n",
            "Epoch 49/50, Loss: 28.65181052684784\n",
            "Epoch 50/50, Loss: 28.20163381099701\n",
            "Epoch 1/50, Loss: 59.920109033584595\n",
            "Epoch 2/50, Loss: 57.30629777908325\n",
            "Epoch 3/50, Loss: 55.564759254455566\n",
            "Epoch 4/50, Loss: 54.6929292678833\n",
            "Epoch 5/50, Loss: 51.83684277534485\n",
            "Epoch 6/50, Loss: 49.10073685646057\n",
            "Epoch 7/50, Loss: 48.823434829711914\n",
            "Epoch 8/50, Loss: 48.16754221916199\n",
            "Epoch 9/50, Loss: 49.12265110015869\n",
            "Epoch 10/50, Loss: 46.70252871513367\n",
            "Epoch 11/50, Loss: 47.2522931098938\n",
            "Epoch 12/50, Loss: 45.883312702178955\n",
            "Epoch 13/50, Loss: 45.465461015701294\n",
            "Epoch 14/50, Loss: 46.3550488948822\n",
            "Epoch 15/50, Loss: 45.31406307220459\n",
            "Epoch 16/50, Loss: 46.48738980293274\n",
            "Epoch 17/50, Loss: 43.59876346588135\n",
            "Epoch 18/50, Loss: 43.91668701171875\n",
            "Epoch 19/50, Loss: 43.933815002441406\n",
            "Epoch 20/50, Loss: 44.75657296180725\n",
            "Epoch 21/50, Loss: 43.152713775634766\n",
            "Epoch 22/50, Loss: 43.959757804870605\n",
            "Epoch 23/50, Loss: 43.44681453704834\n",
            "Epoch 24/50, Loss: 43.88818907737732\n",
            "Epoch 25/50, Loss: 42.90256190299988\n",
            "Epoch 26/50, Loss: 42.041009187698364\n",
            "Epoch 27/50, Loss: 41.012221336364746\n",
            "Epoch 28/50, Loss: 42.75394916534424\n",
            "Epoch 29/50, Loss: 40.80851769447327\n",
            "Epoch 30/50, Loss: 42.66362142562866\n",
            "Epoch 31/50, Loss: 40.66948223114014\n",
            "Epoch 32/50, Loss: 40.73391151428223\n",
            "Epoch 33/50, Loss: 40.188238859176636\n",
            "Epoch 34/50, Loss: 41.087974071502686\n",
            "Epoch 35/50, Loss: 40.847681522369385\n",
            "Epoch 36/50, Loss: 41.05408549308777\n",
            "Epoch 37/50, Loss: 41.1562077999115\n",
            "Epoch 38/50, Loss: 41.06917333602905\n",
            "Epoch 39/50, Loss: 39.63203692436218\n",
            "Epoch 40/50, Loss: 40.631046772003174\n",
            "Epoch 41/50, Loss: 37.96058416366577\n",
            "Epoch 42/50, Loss: 39.9776029586792\n",
            "Epoch 43/50, Loss: 40.24284052848816\n",
            "Epoch 44/50, Loss: 40.405170917510986\n",
            "Epoch 45/50, Loss: 39.76416730880737\n",
            "Epoch 46/50, Loss: 39.270806312561035\n",
            "Epoch 47/50, Loss: 38.477097272872925\n",
            "Epoch 48/50, Loss: 40.527286529541016\n",
            "Epoch 49/50, Loss: 38.51768112182617\n",
            "Epoch 50/50, Loss: 39.207032918930054\n",
            "Epoch 1/50, Loss: 72.78806829452515\n",
            "Epoch 2/50, Loss: 69.9969596862793\n",
            "Epoch 3/50, Loss: 67.64913845062256\n",
            "Epoch 4/50, Loss: 67.47554731369019\n",
            "Epoch 5/50, Loss: 65.54404735565186\n",
            "Epoch 6/50, Loss: 63.807213306427\n",
            "Epoch 7/50, Loss: 60.450820446014404\n",
            "Epoch 8/50, Loss: 60.06561851501465\n",
            "Epoch 9/50, Loss: 60.20346927642822\n",
            "Epoch 10/50, Loss: 59.175639390945435\n",
            "Epoch 11/50, Loss: 57.439220905303955\n",
            "Epoch 12/50, Loss: 58.953449726104736\n",
            "Epoch 13/50, Loss: 57.082160234451294\n",
            "Epoch 14/50, Loss: 56.91841459274292\n",
            "Epoch 15/50, Loss: 56.70673608779907\n",
            "Epoch 16/50, Loss: 56.44041991233826\n",
            "Epoch 17/50, Loss: 56.34329915046692\n",
            "Epoch 18/50, Loss: 55.49890613555908\n",
            "Epoch 19/50, Loss: 54.895366191864014\n",
            "Epoch 20/50, Loss: 54.24217414855957\n",
            "Epoch 21/50, Loss: 54.70751404762268\n",
            "Epoch 22/50, Loss: 53.3330135345459\n",
            "Epoch 23/50, Loss: 54.748465061187744\n",
            "Epoch 24/50, Loss: 54.414572954177856\n",
            "Epoch 25/50, Loss: 54.63378405570984\n",
            "Epoch 26/50, Loss: 54.10340332984924\n",
            "Epoch 27/50, Loss: 53.61014437675476\n",
            "Epoch 28/50, Loss: 52.84976315498352\n",
            "Epoch 29/50, Loss: 54.39406943321228\n",
            "Epoch 30/50, Loss: 52.7323157787323\n",
            "Epoch 31/50, Loss: 53.24158334732056\n",
            "Epoch 32/50, Loss: 52.60021185874939\n",
            "Epoch 33/50, Loss: 53.47567319869995\n",
            "Epoch 34/50, Loss: 50.299100399017334\n",
            "Epoch 35/50, Loss: 51.238202810287476\n",
            "Epoch 36/50, Loss: 52.98496341705322\n",
            "Epoch 37/50, Loss: 51.59559369087219\n",
            "Epoch 38/50, Loss: 52.20306730270386\n",
            "Epoch 39/50, Loss: 52.08569288253784\n",
            "Epoch 40/50, Loss: 51.92599868774414\n",
            "Epoch 41/50, Loss: 51.16644310951233\n",
            "Epoch 42/50, Loss: 51.74809694290161\n",
            "Epoch 43/50, Loss: 50.941511392593384\n",
            "Epoch 44/50, Loss: 50.515777587890625\n",
            "Epoch 45/50, Loss: 49.38240671157837\n",
            "Epoch 46/50, Loss: 51.716832637786865\n",
            "Epoch 47/50, Loss: 50.687461137771606\n",
            "Epoch 48/50, Loss: 49.24197769165039\n",
            "Epoch 49/50, Loss: 51.09929823875427\n",
            "Epoch 50/50, Loss: 51.682941913604736\n",
            "\n",
            "\n",
            "Best Loss Value: 9.300031423568726\n",
            "Best Margin: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this is the helper function to calculate the evaluation of our trained model\n",
        "#I've used mean rank and Hits@10 for this function\n",
        "def evaluate(model, test_triples, all_entities, device='cpu'):\n",
        "    model.eval()\n",
        "    ranks = []\n",
        "    hits_at_10 = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for triple in tqdm(test_triples):\n",
        "            head, relation, tail = triple.tolist()\n",
        "            triple = triple.unsqueeze(0)\n",
        "\n",
        "            # Head Prediction\n",
        "            head_corrupt_list = torch.tensor([[entity, relation, tail] for entity in all_entities], dtype=torch.long)\n",
        "            scores = model.predict(head_corrupt_list.to(device))\n",
        "            _, indices = torch.sort(scores)\n",
        "            rank = (indices == head).nonzero(as_tuple=False).item() + 1\n",
        "            ranks.append(rank)\n",
        "            if rank <= 10:\n",
        "                hits_at_10 += 1\n",
        "\n",
        "            # Tail Prediction\n",
        "            tail_corrupt_list = torch.tensor([[head, relation, entity] for entity in all_entities], dtype=torch.long)\n",
        "            scores = model.predict(tail_corrupt_list.to(device))\n",
        "            _, indices = torch.sort(scores)\n",
        "            rank = (indices == tail).nonzero(as_tuple=False).item() + 1\n",
        "            ranks.append(rank)\n",
        "            if rank <= 10:\n",
        "                hits_at_10 += 1\n",
        "\n",
        "    mean_rank = np.mean(ranks)\n",
        "    hits_at_10_ratio = hits_at_10 / (2 * len(test_triples))\n",
        "\n",
        "    print(f\"Mean Rank (MR): {mean_rank}\")\n",
        "    print(f\"Hits@10: {hits_at_10_ratio}\")\n"
      ],
      "metadata": {
        "id": "ZDEftWwRC0tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate transE model\n",
        "evaluate(transe_model, test_triples.to(device), all_entities, device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWJIRQJ4Dk8s",
        "outputId": "3d9879ad-17f0-44e1-b10a-9b83ac33079f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 201/201 [00:00<00:00, 2183.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Rank (MR): 7.8283582089552235\n",
            "Hits@10: 0.7388059701492538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "ent_embedding_dim = 100\n",
        "rel_embedding_dim = 100\n",
        "margin = 1.0\n",
        "\n",
        "#variables used to get best value of margin\n",
        "best_loss_value = float('inf')\n",
        "best_margin = None\n",
        "best_model = None\n",
        "\n",
        "# loop over margin values\n",
        "for margin in range(1,6):\n",
        "    transr_model = TransR(num_entities, num_relations, ent_embedding_dim, rel_embedding_dim, margin).to()\n",
        "    optimizer = optim.Adam(transr_model.parameters(), lr=0.001)\n",
        "    temp = train_transr(transr_model, optimizer, train_triples.to('cpu'), all_entities, relation_probabilities, num_epochs=50)\n",
        "    if temp < best_loss_value:\n",
        "        best_margin = margin\n",
        "        best_loss_value = temp\n",
        "        best_model = transr_model\n",
        "\n",
        "print(f\"\\n\\nBest Loss Value: {best_loss_value}\")\n",
        "print(f\"Best Margin: {best_margin}\")\n",
        "transr_model = best_model\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JKspJheDpZ3",
        "outputId": "4d0c09de-b366-44b3-b9c5-5091aa9e7505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 13.571379840373993\n",
            "Epoch 2/50, Loss: 12.48416543006897\n",
            "Epoch 3/50, Loss: 11.53985184431076\n",
            "Epoch 4/50, Loss: 12.107122302055359\n",
            "Epoch 5/50, Loss: 11.132291436195374\n",
            "Epoch 6/50, Loss: 10.53265118598938\n",
            "Epoch 7/50, Loss: 10.577868103981018\n",
            "Epoch 8/50, Loss: 9.705206453800201\n",
            "Epoch 9/50, Loss: 9.924059867858887\n",
            "Epoch 10/50, Loss: 9.63907927274704\n",
            "Epoch 11/50, Loss: 9.261480391025543\n",
            "Epoch 12/50, Loss: 9.033979535102844\n",
            "Epoch 13/50, Loss: 9.092665791511536\n",
            "Epoch 14/50, Loss: 9.40879499912262\n",
            "Epoch 15/50, Loss: 9.303705990314484\n",
            "Epoch 16/50, Loss: 8.864585220813751\n",
            "Epoch 17/50, Loss: 8.899981677532196\n",
            "Epoch 18/50, Loss: 8.958638846874237\n",
            "Epoch 19/50, Loss: 9.044651806354523\n",
            "Epoch 20/50, Loss: 9.031903564929962\n",
            "Epoch 21/50, Loss: 8.561208963394165\n",
            "Epoch 22/50, Loss: 8.823433637619019\n",
            "Epoch 23/50, Loss: 8.06762307882309\n",
            "Epoch 24/50, Loss: 8.230264961719513\n",
            "Epoch 25/50, Loss: 8.25392997264862\n",
            "Epoch 26/50, Loss: 8.615049123764038\n",
            "Epoch 27/50, Loss: 8.4046031832695\n",
            "Epoch 28/50, Loss: 8.281666457653046\n",
            "Epoch 29/50, Loss: 8.345796048641205\n",
            "Epoch 30/50, Loss: 8.005017399787903\n",
            "Epoch 31/50, Loss: 8.482922792434692\n",
            "Epoch 32/50, Loss: 8.077380180358887\n",
            "Epoch 33/50, Loss: 8.127821922302246\n",
            "Epoch 34/50, Loss: 8.03804761171341\n",
            "Epoch 35/50, Loss: 8.392634332180023\n",
            "Epoch 36/50, Loss: 7.95971617102623\n",
            "Epoch 37/50, Loss: 8.073262989521027\n",
            "Epoch 38/50, Loss: 7.878195881843567\n",
            "Epoch 39/50, Loss: 7.899266541004181\n",
            "Epoch 40/50, Loss: 7.469411790370941\n",
            "Epoch 41/50, Loss: 7.949594438076019\n",
            "Epoch 42/50, Loss: 7.636556267738342\n",
            "Epoch 43/50, Loss: 7.64019039273262\n",
            "Epoch 44/50, Loss: 8.162405490875244\n",
            "Epoch 45/50, Loss: 7.82256144285202\n",
            "Epoch 46/50, Loss: 7.788181811571121\n",
            "Epoch 47/50, Loss: 7.773221492767334\n",
            "Epoch 48/50, Loss: 7.25078883767128\n",
            "Epoch 49/50, Loss: 7.714652210474014\n",
            "Epoch 50/50, Loss: 7.598530530929565\n",
            "Epoch 1/50, Loss: 26.375471711158752\n",
            "Epoch 2/50, Loss: 23.35573101043701\n",
            "Epoch 3/50, Loss: 22.82499873638153\n",
            "Epoch 4/50, Loss: 21.04262101650238\n",
            "Epoch 5/50, Loss: 21.273164749145508\n",
            "Epoch 6/50, Loss: 19.991323709487915\n",
            "Epoch 7/50, Loss: 19.291727781295776\n",
            "Epoch 8/50, Loss: 18.777663230895996\n",
            "Epoch 9/50, Loss: 18.553322911262512\n",
            "Epoch 10/50, Loss: 17.723093152046204\n",
            "Epoch 11/50, Loss: 18.337037801742554\n",
            "Epoch 12/50, Loss: 17.9520663022995\n",
            "Epoch 13/50, Loss: 17.33686077594757\n",
            "Epoch 14/50, Loss: 17.36864745616913\n",
            "Epoch 15/50, Loss: 17.01498854160309\n",
            "Epoch 16/50, Loss: 16.54903483390808\n",
            "Epoch 17/50, Loss: 16.390278458595276\n",
            "Epoch 18/50, Loss: 16.36532473564148\n",
            "Epoch 19/50, Loss: 16.584632635116577\n",
            "Epoch 20/50, Loss: 16.679927587509155\n",
            "Epoch 21/50, Loss: 16.001566410064697\n",
            "Epoch 22/50, Loss: 15.94804036617279\n",
            "Epoch 23/50, Loss: 16.788100719451904\n",
            "Epoch 24/50, Loss: 15.86790120601654\n",
            "Epoch 25/50, Loss: 16.403105974197388\n",
            "Epoch 26/50, Loss: 16.182619631290436\n",
            "Epoch 27/50, Loss: 15.893081068992615\n",
            "Epoch 28/50, Loss: 15.359859943389893\n",
            "Epoch 29/50, Loss: 15.737401962280273\n",
            "Epoch 30/50, Loss: 15.92699408531189\n",
            "Epoch 31/50, Loss: 15.678352236747742\n",
            "Epoch 32/50, Loss: 15.248457431793213\n",
            "Epoch 33/50, Loss: 15.884531140327454\n",
            "Epoch 34/50, Loss: 14.743687987327576\n",
            "Epoch 35/50, Loss: 14.84209680557251\n",
            "Epoch 36/50, Loss: 15.113427579402924\n",
            "Epoch 37/50, Loss: 14.84981906414032\n",
            "Epoch 38/50, Loss: 14.886282444000244\n",
            "Epoch 39/50, Loss: 15.341961979866028\n",
            "Epoch 40/50, Loss: 14.990945816040039\n",
            "Epoch 41/50, Loss: 14.890703201293945\n",
            "Epoch 42/50, Loss: 14.322576344013214\n",
            "Epoch 43/50, Loss: 15.01752495765686\n",
            "Epoch 44/50, Loss: 15.296854197978973\n",
            "Epoch 45/50, Loss: 15.122281610965729\n",
            "Epoch 46/50, Loss: 15.669373035430908\n",
            "Epoch 47/50, Loss: 14.54714024066925\n",
            "Epoch 48/50, Loss: 15.262778580188751\n",
            "Epoch 49/50, Loss: 15.784139037132263\n",
            "Epoch 50/50, Loss: 14.28876656293869\n",
            "Epoch 1/50, Loss: 38.44131326675415\n",
            "Epoch 2/50, Loss: 33.57671499252319\n",
            "Epoch 3/50, Loss: 33.700780391693115\n",
            "Epoch 4/50, Loss: 31.56428337097168\n",
            "Epoch 5/50, Loss: 31.2819402217865\n",
            "Epoch 6/50, Loss: 29.642813205718994\n",
            "Epoch 7/50, Loss: 29.818637251853943\n",
            "Epoch 8/50, Loss: 29.99199080467224\n",
            "Epoch 9/50, Loss: 28.69904911518097\n",
            "Epoch 10/50, Loss: 27.949350714683533\n",
            "Epoch 11/50, Loss: 26.82990837097168\n",
            "Epoch 12/50, Loss: 26.259557723999023\n",
            "Epoch 13/50, Loss: 25.980680108070374\n",
            "Epoch 14/50, Loss: 25.579627633094788\n",
            "Epoch 15/50, Loss: 25.851474046707153\n",
            "Epoch 16/50, Loss: 24.843488812446594\n",
            "Epoch 17/50, Loss: 24.328409433364868\n",
            "Epoch 18/50, Loss: 24.722190380096436\n",
            "Epoch 19/50, Loss: 24.382927417755127\n",
            "Epoch 20/50, Loss: 25.460538148880005\n",
            "Epoch 21/50, Loss: 24.578455448150635\n",
            "Epoch 22/50, Loss: 23.79976987838745\n",
            "Epoch 23/50, Loss: 23.991822481155396\n",
            "Epoch 24/50, Loss: 22.989825129508972\n",
            "Epoch 25/50, Loss: 23.39208948612213\n",
            "Epoch 26/50, Loss: 23.061594367027283\n",
            "Epoch 27/50, Loss: 22.467212915420532\n",
            "Epoch 28/50, Loss: 23.132022976875305\n",
            "Epoch 29/50, Loss: 23.005329132080078\n",
            "Epoch 30/50, Loss: 24.241483449935913\n",
            "Epoch 31/50, Loss: 22.8943372964859\n",
            "Epoch 32/50, Loss: 23.822383999824524\n",
            "Epoch 33/50, Loss: 22.972865223884583\n",
            "Epoch 34/50, Loss: 22.199689626693726\n",
            "Epoch 35/50, Loss: 23.32384705543518\n",
            "Epoch 36/50, Loss: 21.50370192527771\n",
            "Epoch 37/50, Loss: 23.213178277015686\n",
            "Epoch 38/50, Loss: 21.36806547641754\n",
            "Epoch 39/50, Loss: 23.141289353370667\n",
            "Epoch 40/50, Loss: 22.715559124946594\n",
            "Epoch 41/50, Loss: 22.926443696022034\n",
            "Epoch 42/50, Loss: 22.399603962898254\n",
            "Epoch 43/50, Loss: 23.343549013137817\n",
            "Epoch 44/50, Loss: 21.751525402069092\n",
            "Epoch 45/50, Loss: 21.134159564971924\n",
            "Epoch 46/50, Loss: 23.588611245155334\n",
            "Epoch 47/50, Loss: 21.90347695350647\n",
            "Epoch 48/50, Loss: 22.005704283714294\n",
            "Epoch 49/50, Loss: 21.586735367774963\n",
            "Epoch 50/50, Loss: 21.21660053730011\n",
            "Epoch 1/50, Loss: 51.194730043411255\n",
            "Epoch 2/50, Loss: 45.662293672561646\n",
            "Epoch 3/50, Loss: 44.50226140022278\n",
            "Epoch 4/50, Loss: 44.37339925765991\n",
            "Epoch 5/50, Loss: 40.46089291572571\n",
            "Epoch 6/50, Loss: 40.04661250114441\n",
            "Epoch 7/50, Loss: 40.02449655532837\n",
            "Epoch 8/50, Loss: 37.8092360496521\n",
            "Epoch 9/50, Loss: 37.51470923423767\n",
            "Epoch 10/50, Loss: 36.336408615112305\n",
            "Epoch 11/50, Loss: 36.620404958724976\n",
            "Epoch 12/50, Loss: 34.61007618904114\n",
            "Epoch 13/50, Loss: 36.053203105926514\n",
            "Epoch 14/50, Loss: 32.939263224601746\n",
            "Epoch 15/50, Loss: 32.84859609603882\n",
            "Epoch 16/50, Loss: 33.33987069129944\n",
            "Epoch 17/50, Loss: 33.49083209037781\n",
            "Epoch 18/50, Loss: 32.992581367492676\n",
            "Epoch 19/50, Loss: 32.85916996002197\n",
            "Epoch 20/50, Loss: 32.33680081367493\n",
            "Epoch 21/50, Loss: 34.38090467453003\n",
            "Epoch 22/50, Loss: 31.24565291404724\n",
            "Epoch 23/50, Loss: 31.313369631767273\n",
            "Epoch 24/50, Loss: 31.70840811729431\n",
            "Epoch 25/50, Loss: 31.490180492401123\n",
            "Epoch 26/50, Loss: 32.272913217544556\n",
            "Epoch 27/50, Loss: 32.084925055503845\n",
            "Epoch 28/50, Loss: 30.232813835144043\n",
            "Epoch 29/50, Loss: 30.402140855789185\n",
            "Epoch 30/50, Loss: 31.030818462371826\n",
            "Epoch 31/50, Loss: 30.309717774391174\n",
            "Epoch 32/50, Loss: 30.336655855178833\n",
            "Epoch 33/50, Loss: 30.937429308891296\n",
            "Epoch 34/50, Loss: 30.72488498687744\n",
            "Epoch 35/50, Loss: 31.092661142349243\n",
            "Epoch 36/50, Loss: 29.62437343597412\n",
            "Epoch 37/50, Loss: 31.27496588230133\n",
            "Epoch 38/50, Loss: 31.830251932144165\n",
            "Epoch 39/50, Loss: 28.65511727333069\n",
            "Epoch 40/50, Loss: 28.46094000339508\n",
            "Epoch 41/50, Loss: 30.443531036376953\n",
            "Epoch 42/50, Loss: 30.229764699935913\n",
            "Epoch 43/50, Loss: 29.477839827537537\n",
            "Epoch 44/50, Loss: 30.126638293266296\n",
            "Epoch 45/50, Loss: 29.631627202033997\n",
            "Epoch 46/50, Loss: 28.779417634010315\n",
            "Epoch 47/50, Loss: 27.990254998207092\n",
            "Epoch 48/50, Loss: 28.258986353874207\n",
            "Epoch 49/50, Loss: 30.449511528015137\n",
            "Epoch 50/50, Loss: 29.242369771003723\n",
            "Epoch 1/50, Loss: 64.11226224899292\n",
            "Epoch 2/50, Loss: 58.34068584442139\n",
            "Epoch 3/50, Loss: 54.95576596260071\n",
            "Epoch 4/50, Loss: 53.689300298690796\n",
            "Epoch 5/50, Loss: 50.14659929275513\n",
            "Epoch 6/50, Loss: 51.19601893424988\n",
            "Epoch 7/50, Loss: 50.96735405921936\n",
            "Epoch 8/50, Loss: 50.84135818481445\n",
            "Epoch 9/50, Loss: 49.10125279426575\n",
            "Epoch 10/50, Loss: 47.33512997627258\n",
            "Epoch 11/50, Loss: 46.041292667388916\n",
            "Epoch 12/50, Loss: 45.24274921417236\n",
            "Epoch 13/50, Loss: 44.33018350601196\n",
            "Epoch 14/50, Loss: 43.68909287452698\n",
            "Epoch 15/50, Loss: 43.01169753074646\n",
            "Epoch 16/50, Loss: 42.47407793998718\n",
            "Epoch 17/50, Loss: 41.92935037612915\n",
            "Epoch 18/50, Loss: 41.548457622528076\n",
            "Epoch 19/50, Loss: 40.03111505508423\n",
            "Epoch 20/50, Loss: 41.49180221557617\n",
            "Epoch 21/50, Loss: 40.32252264022827\n",
            "Epoch 22/50, Loss: 40.49006366729736\n",
            "Epoch 23/50, Loss: 40.499093532562256\n",
            "Epoch 24/50, Loss: 41.71176290512085\n",
            "Epoch 25/50, Loss: 39.72971057891846\n",
            "Epoch 26/50, Loss: 39.650370359420776\n",
            "Epoch 27/50, Loss: 39.35955095291138\n",
            "Epoch 28/50, Loss: 37.939908027648926\n",
            "Epoch 29/50, Loss: 41.00566482543945\n",
            "Epoch 30/50, Loss: 37.857967138290405\n",
            "Epoch 31/50, Loss: 36.811299324035645\n",
            "Epoch 32/50, Loss: 37.24792265892029\n",
            "Epoch 33/50, Loss: 39.12532067298889\n",
            "Epoch 34/50, Loss: 37.520548582077026\n",
            "Epoch 35/50, Loss: 36.97957944869995\n",
            "Epoch 36/50, Loss: 37.815510511398315\n",
            "Epoch 37/50, Loss: 39.453612327575684\n",
            "Epoch 38/50, Loss: 35.866617918014526\n",
            "Epoch 39/50, Loss: 36.96055054664612\n",
            "Epoch 40/50, Loss: 37.757766008377075\n",
            "Epoch 41/50, Loss: 37.51272964477539\n",
            "Epoch 42/50, Loss: 37.80371356010437\n",
            "Epoch 43/50, Loss: 36.90852618217468\n",
            "Epoch 44/50, Loss: 35.74376559257507\n",
            "Epoch 45/50, Loss: 36.98614811897278\n",
            "Epoch 46/50, Loss: 35.98807740211487\n",
            "Epoch 47/50, Loss: 35.82693290710449\n",
            "Epoch 48/50, Loss: 36.13492560386658\n",
            "Epoch 49/50, Loss: 35.274173974990845\n",
            "Epoch 50/50, Loss: 35.72005295753479\n",
            "\n",
            "\n",
            "Best Loss Value: 7.598530530929565\n",
            "Best Margin: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "evaluate(transr_model, test_triples.to(device), all_entities, device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5W0Sa07B8cu",
        "outputId": "88418fe1-1ea4-4ebb-93f7-06c625534d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 201/201 [00:00<00:00, 987.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Rank (MR): 7.925373134328358\n",
            "Hits@10: 0.7189054726368159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TransE and TransR for Kinships Dataset"
      ],
      "metadata": {
        "id": "ee4fPoYvAmPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data to train models\n",
        "train_triples = kinships_train_triples\n",
        "test_triples = kinships_test_triples\n",
        "\n",
        "num_entities = len(kinships_entity2id)\n",
        "num_relations = len(kinships_relation2id)\n",
        "all_entities = list(range(num_entities))\n",
        "\n",
        "# Calculate relation probabilities\n",
        "relation_probabilities = calculate_relation_probabilities(train_triples, num_relations)\n",
        "\n",
        "# Initialize model\n",
        "embedding_dim = 100\n",
        "margin = 1.0\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "transe_model = TransE(num_entities, num_relations, embedding_dim, margin).to(device)\n",
        "optimizer = optim.Adam(transe_model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "train_transe(transe_model, optimizer, train_triples.to(device), all_entities, relation_probabilities, num_epochs=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arKHpuuvKa4g",
        "outputId": "296ff0e1-7d1d-43ae-ce1c-94bf48d3c0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 75.96081733703613\n",
            "Epoch 2/50, Loss: 70.85033160448074\n",
            "Epoch 3/50, Loss: 64.99201929569244\n",
            "Epoch 4/50, Loss: 61.55555480718613\n",
            "Epoch 5/50, Loss: 58.221709191799164\n",
            "Epoch 6/50, Loss: 54.45144200325012\n",
            "Epoch 7/50, Loss: 51.325800478458405\n",
            "Epoch 8/50, Loss: 49.50693333148956\n",
            "Epoch 9/50, Loss: 46.491590321063995\n",
            "Epoch 10/50, Loss: 45.21829932928085\n",
            "Epoch 11/50, Loss: 43.61549097299576\n",
            "Epoch 12/50, Loss: 42.0093629360199\n",
            "Epoch 13/50, Loss: 40.42376929521561\n",
            "Epoch 14/50, Loss: 38.916792660951614\n",
            "Epoch 15/50, Loss: 36.6746484041214\n",
            "Epoch 16/50, Loss: 35.3532457947731\n",
            "Epoch 17/50, Loss: 33.85575222969055\n",
            "Epoch 18/50, Loss: 32.46593105792999\n",
            "Epoch 19/50, Loss: 30.53354439139366\n",
            "Epoch 20/50, Loss: 29.69814494252205\n",
            "Epoch 21/50, Loss: 28.0881527364254\n",
            "Epoch 22/50, Loss: 27.46469196677208\n",
            "Epoch 23/50, Loss: 25.893169939517975\n",
            "Epoch 24/50, Loss: 24.944531708955765\n",
            "Epoch 25/50, Loss: 23.32453542947769\n",
            "Epoch 26/50, Loss: 23.679474413394928\n",
            "Epoch 27/50, Loss: 22.102417573332787\n",
            "Epoch 28/50, Loss: 21.904126286506653\n",
            "Epoch 29/50, Loss: 21.17070773243904\n",
            "Epoch 30/50, Loss: 20.686899214982986\n",
            "Epoch 31/50, Loss: 20.633379101753235\n",
            "Epoch 32/50, Loss: 20.22926437854767\n",
            "Epoch 33/50, Loss: 19.37046752870083\n",
            "Epoch 34/50, Loss: 18.486301705241203\n",
            "Epoch 35/50, Loss: 18.873532712459564\n",
            "Epoch 36/50, Loss: 19.334838911890984\n",
            "Epoch 37/50, Loss: 18.54945032298565\n",
            "Epoch 38/50, Loss: 18.56580138206482\n",
            "Epoch 39/50, Loss: 17.96603697538376\n",
            "Epoch 40/50, Loss: 17.60388208925724\n",
            "Epoch 41/50, Loss: 17.6054640263319\n",
            "Epoch 42/50, Loss: 17.403770074248314\n",
            "Epoch 43/50, Loss: 17.745567440986633\n",
            "Epoch 44/50, Loss: 17.122546151280403\n",
            "Epoch 45/50, Loss: 17.193610429763794\n",
            "Epoch 46/50, Loss: 17.661325693130493\n",
            "Epoch 47/50, Loss: 16.567702755331993\n",
            "Epoch 48/50, Loss: 17.07301662862301\n",
            "Epoch 49/50, Loss: 16.929948210716248\n",
            "Epoch 50/50, Loss: 16.71028082072735\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.71028082072735"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "evaluate(transe_model, test_triples.to(device), all_entities, device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kELgYrswKv0X",
        "outputId": "3f0fa0da-fef8-4a17-b859-3859aa88f60a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1074/1074 [00:01<00:00, 974.75it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Rank (MR): 18.869180633147113\n",
            "Hits@10: 0.38594040968342647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "ent_embedding_dim = 100\n",
        "rel_embedding_dim = 100\n",
        "margin = 1.0\n",
        "\n",
        "#initialize model\n",
        "transr_model = TransR(num_entities, num_relations, ent_embedding_dim, rel_embedding_dim, margin).to('cuda')\n",
        "optimizer = optim.Adam(transr_model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "train_transr(transr_model, optimizer, train_triples.to('cuda'), all_entities, relation_probabilities, num_epochs=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCyrGFm9CPQc",
        "outputId": "2ef93a94-5281-4974-f15d-6519687b016b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 62.03486913442612\n",
            "Epoch 2/50, Loss: 53.098584711551666\n",
            "Epoch 3/50, Loss: 50.59277015924454\n",
            "Epoch 4/50, Loss: 45.1336150765419\n",
            "Epoch 5/50, Loss: 39.97628811001778\n",
            "Epoch 6/50, Loss: 33.09869307279587\n",
            "Epoch 7/50, Loss: 27.955332189798355\n",
            "Epoch 8/50, Loss: 24.845732405781746\n",
            "Epoch 9/50, Loss: 21.950996696949005\n",
            "Epoch 10/50, Loss: 20.999788865447044\n",
            "Epoch 11/50, Loss: 19.38080134987831\n",
            "Epoch 12/50, Loss: 19.02596041560173\n",
            "Epoch 13/50, Loss: 18.343090519309044\n",
            "Epoch 14/50, Loss: 18.987951293587685\n",
            "Epoch 15/50, Loss: 18.08624741435051\n",
            "Epoch 16/50, Loss: 17.952115163207054\n",
            "Epoch 17/50, Loss: 17.910125613212585\n",
            "Epoch 18/50, Loss: 17.185912653803825\n",
            "Epoch 19/50, Loss: 16.589973211288452\n",
            "Epoch 20/50, Loss: 17.32637958228588\n",
            "Epoch 21/50, Loss: 17.348295107483864\n",
            "Epoch 22/50, Loss: 16.801802575588226\n",
            "Epoch 23/50, Loss: 16.934081971645355\n",
            "Epoch 24/50, Loss: 16.101079791784286\n",
            "Epoch 25/50, Loss: 15.792932078242302\n",
            "Epoch 26/50, Loss: 15.455307930707932\n",
            "Epoch 27/50, Loss: 15.310247123241425\n",
            "Epoch 28/50, Loss: 15.226847767829895\n",
            "Epoch 29/50, Loss: 15.45400433987379\n",
            "Epoch 30/50, Loss: 16.10646779835224\n",
            "Epoch 31/50, Loss: 14.537894666194916\n",
            "Epoch 32/50, Loss: 15.318459421396255\n",
            "Epoch 33/50, Loss: 15.684630565345287\n",
            "Epoch 34/50, Loss: 15.354828797280788\n",
            "Epoch 35/50, Loss: 15.467672899365425\n",
            "Epoch 36/50, Loss: 15.366471067070961\n",
            "Epoch 37/50, Loss: 15.095730885863304\n",
            "Epoch 38/50, Loss: 15.665748998522758\n",
            "Epoch 39/50, Loss: 15.066612794995308\n",
            "Epoch 40/50, Loss: 14.054138146340847\n",
            "Epoch 41/50, Loss: 14.491508387029171\n",
            "Epoch 42/50, Loss: 14.82340394705534\n",
            "Epoch 43/50, Loss: 14.671670913696289\n",
            "Epoch 44/50, Loss: 14.70844004303217\n",
            "Epoch 45/50, Loss: 13.474632449448109\n",
            "Epoch 46/50, Loss: 13.69477590918541\n",
            "Epoch 47/50, Loss: 13.95814161002636\n",
            "Epoch 48/50, Loss: 14.16745524853468\n",
            "Epoch 49/50, Loss: 13.706712618470192\n",
            "Epoch 50/50, Loss: 14.207392647862434\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.207392647862434"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "evaluate(transr_model, test_triples.to('cuda'), all_entities, device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0SqyyueCnZX",
        "outputId": "fd08f2e1-947a-4f92-b9e9-c5ee49a13b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1074/1074 [00:01<00:00, 875.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Rank (MR): 14.854283054003725\n",
            "Hits@10: 0.45996275605214154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Similar Fact retrieval***"
      ],
      "metadata": {
        "id": "0Rjgrg_0u6Rg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#given validation triplets\n",
        "validation_triples = [\n",
        "    ['brazil', 'commonbloc1', 'india'],\n",
        "    ['burma', 'intergovorgs3', 'indonesia'],\n",
        "    ['china', 'accusation', 'uk'],\n",
        "    ['cuba', 'reldiplomacy', 'china'],\n",
        "    ['egypt', 'embassy', 'uk']\n",
        "]\n"
      ],
      "metadata": {
        "id": "O8tZaFQNLFB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entity2id = nations_entity2id\n",
        "relation2id = nations_relation2id\n",
        "\n",
        "# Function to get triple embedding (model will be giving 30 dimension representation)\n",
        "def get_triple_embedding(model, triple):\n",
        "    h_id = torch.tensor([entity2id[triple[0]]], dtype=torch.long).to('cpu')\n",
        "    r_id = torch.tensor([relation2id[triple[1]]], dtype=torch.long).to('cpu')\n",
        "    t_id = torch.tensor([entity2id[triple[2]]], dtype=torch.long).to('cpu')\n",
        "\n",
        "    if isinstance(model, TransE):\n",
        "        h_emb = model.entity_embeddings(h_id)\n",
        "        r_emb = model.relation_embeddings(r_id)\n",
        "        t_emb = model.entity_embeddings(t_id)\n",
        "        triple_emb = h_emb + r_emb - t_emb\n",
        "    elif isinstance(model, TransR):\n",
        "        h_emb = model.entity_embeddings(h_id)\n",
        "        r_emb = model.relation_embeddings(r_id)\n",
        "        t_emb = model.entity_embeddings(t_id)\n",
        "        proj = model.proj_matrices(r_id).view(-1, model.rel_embedding_dim, model.ent_embedding_dim)\n",
        "        h_proj = torch.bmm(proj, h_emb.unsqueeze(2)).squeeze(2)\n",
        "        t_proj = torch.bmm(proj, t_emb.unsqueeze(2)).squeeze(2)\n",
        "        triple_emb = h_proj + r_emb - t_proj\n",
        "    return triple_emb.squeeze(0).cpu().detach().numpy()\n"
      ],
      "metadata": {
        "id": "y2bks0OELIpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all triples in the dataset\n",
        "all_triples = torch.cat([nations_train_triples, nations_valid_triples, nations_test_triples], dim=0)\n",
        "\n",
        "# Compute embeddings for all triples\n",
        "def compute_all_triple_embeddings(model, all_triples):\n",
        "    triple_embeddings = []\n",
        "    for triple in all_triples:\n",
        "        h, r, t = triple.tolist()\n",
        "        h_emb = model.entity_embeddings(torch.tensor([h]).to('cpu'))\n",
        "        r_emb = model.relation_embeddings(torch.tensor([r]).to('cpu'))\n",
        "        t_emb = model.entity_embeddings(torch.tensor([t]).to('cpu'))\n",
        "\n",
        "        if isinstance(model, TransE):\n",
        "            triple_emb = h_emb + r_emb - t_emb\n",
        "        elif isinstance(model, TransR):\n",
        "            proj = model.proj_matrices(torch.tensor([r]).to('cpu')).view(-1, model.rel_embedding_dim, model.ent_embedding_dim)\n",
        "            h_proj = torch.bmm(proj, h_emb.unsqueeze(2)).squeeze(2)\n",
        "            t_proj = torch.bmm(proj, t_emb.unsqueeze(2)).squeeze(2)\n",
        "            triple_emb = h_proj + r_emb - t_proj\n",
        "\n",
        "        triple_embeddings.append(triple_emb.squeeze(0).cpu().detach().numpy())\n",
        "    return np.array(triple_embeddings)\n"
      ],
      "metadata": {
        "id": "E8ySoWUeLL05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to retrieve similar facts based on dot product similarity\n",
        "def retrieve_similar_facts(model, validation_triples, all_triples, triple_embeddings):\n",
        "    similar_facts = {}\n",
        "    for triple in validation_triples:\n",
        "        triple_emb = get_triple_embedding(model, triple)\n",
        "        # Compute dot-product similarity\n",
        "        similarities = np.dot(triple_embeddings, triple_emb)\n",
        "        # Get top-5 indices\n",
        "        top_indices = similarities.argsort()[-5:][::-1]\n",
        "        top_triples = [all_triples[i].tolist() for i in top_indices]\n",
        "        similar_facts[tuple(triple)] = top_triples\n",
        "    return similar_facts\n"
      ],
      "metadata": {
        "id": "qiYq7m8OLOc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#I need to retrain the transE model to get a 30 dimension embedding of the given triples\n",
        "# Prepare data\n",
        "train_triples = nations_train_triples\n",
        "test_triples = nations_test_triples\n",
        "\n",
        "num_entities = len(nations_entity2id)\n",
        "num_relations = len(nations_relation2id)\n",
        "all_entities = list(range(num_entities))\n",
        "\n",
        "# Calculate relation probabilities\n",
        "relation_probabilities = calculate_relation_probabilities(train_triples, num_relations)\n",
        "\n",
        "# Initialize model\n",
        "embedding_dim = 30\n",
        "margin = 1.0  # Vary from 1.0 to 5.0 for Nations dataset\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "transe_model = TransE(num_entities, num_relations, embedding_dim, margin).to('cpu')\n",
        "optimizer = optim.Adam(transe_model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "train_transe(transe_model, optimizer, train_triples.to('cpu'), all_entities, relation_probabilities, num_epochs=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXhUWq46tqPX",
        "outputId": "50ea9998-9df4-42bb-e7d7-7edceafb9397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 18.350502014160156\n",
            "Epoch 2/50, Loss: 18.544556617736816\n",
            "Epoch 3/50, Loss: 17.376468062400818\n",
            "Epoch 4/50, Loss: 16.471715807914734\n",
            "Epoch 5/50, Loss: 16.55157172679901\n",
            "Epoch 6/50, Loss: 15.500734210014343\n",
            "Epoch 7/50, Loss: 15.374982953071594\n",
            "Epoch 8/50, Loss: 15.250616014003754\n",
            "Epoch 9/50, Loss: 15.148805141448975\n",
            "Epoch 10/50, Loss: 14.216460704803467\n",
            "Epoch 11/50, Loss: 14.026033222675323\n",
            "Epoch 12/50, Loss: 13.74786752462387\n",
            "Epoch 13/50, Loss: 13.826295614242554\n",
            "Epoch 14/50, Loss: 14.069172263145447\n",
            "Epoch 15/50, Loss: 13.159949779510498\n",
            "Epoch 16/50, Loss: 13.752584636211395\n",
            "Epoch 17/50, Loss: 13.531367778778076\n",
            "Epoch 18/50, Loss: 13.123306214809418\n",
            "Epoch 19/50, Loss: 13.095493793487549\n",
            "Epoch 20/50, Loss: 13.150041937828064\n",
            "Epoch 21/50, Loss: 12.582712233066559\n",
            "Epoch 22/50, Loss: 13.058550596237183\n",
            "Epoch 23/50, Loss: 12.870498180389404\n",
            "Epoch 24/50, Loss: 12.03838860988617\n",
            "Epoch 25/50, Loss: 11.983310520648956\n",
            "Epoch 26/50, Loss: 12.238919854164124\n",
            "Epoch 27/50, Loss: 11.954380810260773\n",
            "Epoch 28/50, Loss: 12.242343842983246\n",
            "Epoch 29/50, Loss: 11.843956232070923\n",
            "Epoch 30/50, Loss: 12.085540890693665\n",
            "Epoch 31/50, Loss: 11.762713968753815\n",
            "Epoch 32/50, Loss: 11.847904741764069\n",
            "Epoch 33/50, Loss: 11.801681280136108\n",
            "Epoch 34/50, Loss: 11.764655947685242\n",
            "Epoch 35/50, Loss: 11.26423978805542\n",
            "Epoch 36/50, Loss: 11.494633495807648\n",
            "Epoch 37/50, Loss: 11.596017479896545\n",
            "Epoch 38/50, Loss: 11.312372386455536\n",
            "Epoch 39/50, Loss: 10.849657773971558\n",
            "Epoch 40/50, Loss: 11.147166192531586\n",
            "Epoch 41/50, Loss: 10.913417220115662\n",
            "Epoch 42/50, Loss: 10.906059384346008\n",
            "Epoch 43/50, Loss: 10.914245903491974\n",
            "Epoch 44/50, Loss: 10.806440830230713\n",
            "Epoch 45/50, Loss: 11.086490392684937\n",
            "Epoch 46/50, Loss: 10.604683756828308\n",
            "Epoch 47/50, Loss: 10.394939064979553\n",
            "Epoch 48/50, Loss: 10.89896535873413\n",
            "Epoch 49/50, Loss: 10.882158160209656\n",
            "Epoch 50/50, Loss: 10.172553837299347\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.172553837299347"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute embeddings for all triples\n",
        "triple_embeddings = compute_all_triple_embeddings(transe_model, all_triples)\n",
        "\n",
        "# Retrieve similar facts using TransE\n",
        "transe_similar_facts = retrieve_similar_facts(transe_model, validation_triples, all_triples, triple_embeddings)\n",
        "\n",
        "# Now for TransR, first retrain with embedding_dim=30\n",
        "# Initialize model\n",
        "ent_embedding_dim = 30\n",
        "rel_embedding_dim = 30\n",
        "margin = 1.0\n",
        "\n",
        "transr_model = TransR(num_entities, num_relations, ent_embedding_dim, rel_embedding_dim, margin).to('cpu')\n",
        "optimizer = optim.Adam(transr_model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "train_transr(transr_model, optimizer, train_triples.to('cpu'), all_entities, relation_probabilities, num_epochs=50)\n",
        "\n",
        "# Compute embeddings for all triples\n",
        "triple_embeddings = compute_all_triple_embeddings(transr_model, all_triples)\n",
        "\n",
        "# Retrieve similar facts using TransR\n",
        "transr_similar_facts = retrieve_similar_facts(transr_model, validation_triples, all_triples, triple_embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNB00dbMLQ1X",
        "outputId": "8c2c1e40-78bf-479f-f2e4-8ab281da6678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 13.180599927902222\n",
            "Epoch 2/50, Loss: 12.072459280490875\n",
            "Epoch 3/50, Loss: 11.412011086940765\n",
            "Epoch 4/50, Loss: 10.575494408607483\n",
            "Epoch 5/50, Loss: 10.267481029033661\n",
            "Epoch 6/50, Loss: 10.155626952648163\n",
            "Epoch 7/50, Loss: 9.819883584976196\n",
            "Epoch 8/50, Loss: 9.756820857524872\n",
            "Epoch 9/50, Loss: 9.368657171726227\n",
            "Epoch 10/50, Loss: 9.058524370193481\n",
            "Epoch 11/50, Loss: 9.18533307313919\n",
            "Epoch 12/50, Loss: 8.892211735248566\n",
            "Epoch 13/50, Loss: 8.686697661876678\n",
            "Epoch 14/50, Loss: 8.920175194740295\n",
            "Epoch 15/50, Loss: 8.570436835289001\n",
            "Epoch 16/50, Loss: 8.417959153652191\n",
            "Epoch 17/50, Loss: 8.545351684093475\n",
            "Epoch 18/50, Loss: 8.521060347557068\n",
            "Epoch 19/50, Loss: 8.076442450284958\n",
            "Epoch 20/50, Loss: 8.049269258975983\n",
            "Epoch 21/50, Loss: 8.251438856124878\n",
            "Epoch 22/50, Loss: 7.981075584888458\n",
            "Epoch 23/50, Loss: 7.764026880264282\n",
            "Epoch 24/50, Loss: 8.012554705142975\n",
            "Epoch 25/50, Loss: 7.81001552939415\n",
            "Epoch 26/50, Loss: 7.860036253929138\n",
            "Epoch 27/50, Loss: 7.9782445430755615\n",
            "Epoch 28/50, Loss: 7.710600554943085\n",
            "Epoch 29/50, Loss: 8.386263966560364\n",
            "Epoch 30/50, Loss: 7.828900694847107\n",
            "Epoch 31/50, Loss: 7.327502280473709\n",
            "Epoch 32/50, Loss: 7.483602464199066\n",
            "Epoch 33/50, Loss: 7.745095610618591\n",
            "Epoch 34/50, Loss: 7.686613142490387\n",
            "Epoch 35/50, Loss: 7.573936641216278\n",
            "Epoch 36/50, Loss: 7.158169656991959\n",
            "Epoch 37/50, Loss: 7.767746925354004\n",
            "Epoch 38/50, Loss: 7.135032743215561\n",
            "Epoch 39/50, Loss: 7.694737136363983\n",
            "Epoch 40/50, Loss: 7.400720477104187\n",
            "Epoch 41/50, Loss: 7.238917171955109\n",
            "Epoch 42/50, Loss: 7.257966488599777\n",
            "Epoch 43/50, Loss: 7.418022900819778\n",
            "Epoch 44/50, Loss: 7.117474466562271\n",
            "Epoch 45/50, Loss: 7.254168152809143\n",
            "Epoch 46/50, Loss: 7.236029386520386\n",
            "Epoch 47/50, Loss: 6.972039312124252\n",
            "Epoch 48/50, Loss: 7.323886752128601\n",
            "Epoch 49/50, Loss: 6.806814640760422\n",
            "Epoch 50/50, Loss: 7.127203613519669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse mappings\n",
        "id2entity = {v: k for k, v in entity2id.items()}\n",
        "id2relation = {v: k for k, v in relation2id.items()}\n",
        "\n",
        "def map_triples(triples_list):\n",
        "    mapped_triples = []\n",
        "    for triple in triples_list:\n",
        "        h, r, t = triple\n",
        "        mapped_triples.append([id2entity[h], id2relation[r], id2entity[t]])\n",
        "    return mapped_triples\n"
      ],
      "metadata": {
        "id": "9en7iX-UMeh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display TransE Similar Facts\n",
        "print(\"Similar Facts using TransE:\")\n",
        "for triple, similar_triples in transe_similar_facts.items():\n",
        "    print(f\"\\nValidation Triple: {triple}\")\n",
        "    mapped_triples = map_triples(similar_triples)\n",
        "    for i, t in enumerate(mapped_triples):\n",
        "        print(f\"Top {i+1}: {t}\")\n",
        "\n",
        "# Display TransR Similar Facts\n",
        "print(\"\\nSimilar Facts using TransR:\")\n",
        "for triple, similar_triples in transr_similar_facts.items():\n",
        "    print(f\"\\nValidation Triple: {triple}\")\n",
        "    mapped_triples = map_triples(similar_triples)\n",
        "    for i, t in enumerate(mapped_triples):\n",
        "        print(f\"Top {i+1}: {t}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v9vp9I_w5mZ",
        "outputId": "d5949f77-fa25-4295-d60f-84b4d0b02516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar Facts using TransE:\n",
            "\n",
            "Validation Triple: ('brazil', 'commonbloc1', 'india')\n",
            "Top 1: ['brazil', 'commonbloc1', 'india']\n",
            "Top 2: ['brazil', 'commonbloc1', 'indonesia']\n",
            "Top 3: ['brazil', 'commonbloc1', 'burma']\n",
            "Top 4: ['poland', 'commonbloc1', 'india']\n",
            "Top 5: ['brazil', 'commonbloc1', 'israel']\n",
            "\n",
            "Validation Triple: ('burma', 'intergovorgs3', 'indonesia')\n",
            "Top 1: ['burma', 'intergovorgs3', 'indonesia']\n",
            "Top 2: ['india', 'intergovorgs3', 'indonesia']\n",
            "Top 3: ['burma', 'intergovorgs3', 'netherlands']\n",
            "Top 4: ['burma', 'embassy', 'indonesia']\n",
            "Top 5: ['burma', 'intergovorgs3', 'brazil']\n",
            "\n",
            "Validation Triple: ('china', 'accusation', 'uk')\n",
            "Top 1: ['china', 'accusation', 'uk']\n",
            "Top 2: ['china', 'accusation', 'ussr']\n",
            "Top 3: ['china', 'accusation', 'indonesia']\n",
            "Top 4: ['china', 'accusation', 'usa']\n",
            "Top 5: ['china', 'accusation', 'india']\n",
            "\n",
            "Validation Triple: ('cuba', 'reldiplomacy', 'china')\n",
            "Top 1: ['cuba', 'reldiplomacy', 'china']\n",
            "Top 2: ['cuba', 'reldiplomacy', 'india']\n",
            "Top 3: ['cuba', 'reldiplomacy', 'ussr']\n",
            "Top 4: ['cuba', 'reldiplomacy', 'poland']\n",
            "Top 5: ['cuba', 'reldiplomacy', 'egypt']\n",
            "\n",
            "Validation Triple: ('egypt', 'embassy', 'uk')\n",
            "Top 1: ['egypt', 'embassy', 'netherlands']\n",
            "Top 2: ['egypt', 'embassy', 'uk']\n",
            "Top 3: ['egypt', 'embassy', 'indonesia']\n",
            "Top 4: ['egypt', 'embassy', 'ussr']\n",
            "Top 5: ['egypt', 'embassy', 'poland']\n",
            "\n",
            "Similar Facts using TransR:\n",
            "\n",
            "Validation Triple: ('brazil', 'commonbloc1', 'india')\n",
            "Top 1: ['brazil', 'commonbloc1', 'india']\n",
            "Top 2: ['brazil', 'commonbloc1', 'indonesia']\n",
            "Top 3: ['brazil', 'commonbloc1', 'burma']\n",
            "Top 4: ['egypt', 'commonbloc1', 'cuba']\n",
            "Top 5: ['jordan', 'commonbloc1', 'cuba']\n",
            "\n",
            "Validation Triple: ('burma', 'intergovorgs3', 'indonesia')\n",
            "Top 1: ['burma', 'intergovorgs3', 'indonesia']\n",
            "Top 2: ['brazil', 'intergovorgs3', 'cuba']\n",
            "Top 3: ['india', 'intergovorgs3', 'indonesia']\n",
            "Top 4: ['usa', 'intergovorgs3', 'cuba']\n",
            "Top 5: ['uk', 'intergovorgs3', 'poland']\n",
            "\n",
            "Validation Triple: ('china', 'accusation', 'uk')\n",
            "Top 1: ['china', 'accusation', 'uk']\n",
            "Top 2: ['indonesia', 'accusation', 'uk']\n",
            "Top 3: ['china', 'accusation', 'india']\n",
            "Top 4: ['china', 'accusation', 'ussr']\n",
            "Top 5: ['usa', 'accusation', 'ussr']\n",
            "\n",
            "Validation Triple: ('cuba', 'reldiplomacy', 'china')\n",
            "Top 1: ['indonesia', 'reldiplomacy', 'brazil']\n",
            "Top 2: ['burma', 'reldiplomacy', 'egypt']\n",
            "Top 3: ['indonesia', 'reldiplomacy', 'egypt']\n",
            "Top 4: ['jordan', 'reldiplomacy', 'egypt']\n",
            "Top 5: ['cuba', 'reldiplomacy', 'egypt']\n",
            "\n",
            "Validation Triple: ('egypt', 'embassy', 'uk')\n",
            "Top 1: ['egypt', 'embassy', 'uk']\n",
            "Top 2: ['china', 'embassy', 'uk']\n",
            "Top 3: ['egypt', 'embassy', 'cuba']\n",
            "Top 4: ['egypt', 'embassy', 'usa']\n",
            "Top 5: ['india', 'embassy', 'uk']\n"
          ]
        }
      ]
    }
  ]
}